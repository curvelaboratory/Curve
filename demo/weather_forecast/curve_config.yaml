version: "0.1-beta"

listener:
  address: 0.0.0.0
  port: 10000
  message_format: huggingface
  connect_timeout: 0.005s

endpoints:
  weather_forecast_service:
    endpoint: host.docker.internal:18083
    connect_timeout: 0.005s

overrides:
  # confidence threshold for prompt target intent matching
  prompt_target_intent_matching_threshold: 0.6

llm_providers:
  - name: gpt-4o-mini
    access_key: $OPENAI_API_KEY
    provider: openai
    model: gpt-4o-mini
    default: true

  - name: gpt-3.5-turbo-0125
    access_key: $OPENAI_API_KEY
    provider: openai
    model: gpt-3.5-turbo-0125

  - name: gpt-4o
    access_key: $OPENAI_API_KEY
    provider: openai
    model: gpt-4o

system_prompt: |
  You are a helpful assistant.

prompt_targets:
  - name: weather_forecast
    description: Check weather information for a given city.
    parameters:
      - name: city
        description: the name of the city
        required: true
        type: str
      - name: days
        description: the number of days
        type: int
        required: true
      - name: units
        description: the temperature unit, e.g., Celsius and Fahrenheit
        type: str
        default: Fahrenheit
    endpoint:
      name: weather_forecast_service
      path: /weather

  - name: default_target
    default: true
    description: This is the default target for all unmatched prompts.
    endpoint:
      name: weather_forecast_service
      path: /default_target
    system_prompt: |
      You are a helpful assistant! Summarize the user's request and provide a helpful response.
    # if it is set to false curve  will send response that it received from this prompt target to the user
    # if true curve  will forward the response to the default LLM
    auto_llm_dispatch_on_response: false

tracing:
  random_sampling: 100
  trace_curve _internal: true
